{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing listing page https://www.kaggle.com/jobs/16785\n",
      "Processing listing page https://www.kaggle.com/jobs/16835\n",
      "Processing listing page https://www.kaggle.com/jobs/16885\n",
      "Processing listing page https://www.kaggle.com/jobs/16935\n",
      "Processing listing page https://www.kaggle.com/jobs/16985\n",
      "Processing listing page https://www.kaggle.com/jobs/17035\n",
      "Processing listing page https://www.kaggle.com/jobs/17085\n",
      "Error getting listing details for: https://www.kaggle.com/jobs/17085\n",
      "Done processing job listings\n",
      "                                       alert_message  body_p  \\\n",
      "0  This job post has expired (either the position...       5   \n",
      "1  This job post has expired (either the position...      10   \n",
      "2  This job post has expired (either the position...      20   \n",
      "3  This job post has expired (either the position...      19   \n",
      "4  This job post has expired (either the position...      19   \n",
      "\n",
      "                                            body_raw  body_ul      company  \\\n",
      "0  \\r\\n    Posted 6 months ago (1,841 views)\\r\\n ...        2   DataRobot    \n",
      "1  \\r\\n    Posted 5 months ago (1,614 views)\\r\\n ...        2     AppLovin   \n",
      "2  \\r\\n    Posted 4 months ago (551 views)\\r\\n   ...        0  Capital One   \n",
      "3  \\r\\n    Posted 3 months ago (1,260 views)\\r\\n ...        3    CrossLend   \n",
      "4  \\r\\n    Posted 2 months ago (1,499 views)\\r\\n ...        0       msg.ai   \n",
      "\n",
      "   job_id                                          job_title       location  \\\n",
      "0   16785                                     Data Scientist          Japan   \n",
      "1   16835                                     Data Scientist      Palo Alto   \n",
      "2   16885                      Digital Data Analysis Manager   Richmond, VA   \n",
      "3   16935        Senior Python Developer - Data Science Team         Berlin   \n",
      "4   16985  Data Scientist / Machine Learning / NLP at Y-C...  San Francisco   \n",
      "\n",
      "                   post_date  status_code views  \n",
      "0   10/9/2015 9:16:55 AM UTC          200  1841  \n",
      "1  11/4/2015 12:35:05 AM UTC          200  1614  \n",
      "2   12/1/2015 6:07:46 PM UTC          200   551  \n",
      "3    1/5/2016 2:43:43 PM UTC          200  1260  \n",
      "4    2/3/2016 3:33:27 AM UTC          200  1499  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import lxml.html\n",
    "from lxml.html.clean import Cleaner\n",
    "import re\n",
    "#import json\n",
    "from time import sleep\n",
    "from random import randint\n",
    "import csv\n",
    "\n",
    "\n",
    "def parse_job_listings(start=17100, end=17101, interval=1):\n",
    "    \n",
    "    listing_base_url = 'https://www.kaggle.com/jobs/'\n",
    "    headers = {'User-agent':'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1'}\n",
    "\n",
    "    main_results = []\n",
    "\n",
    "    for _listing in range(start, end, interval):\n",
    "    \n",
    "        _dat = {}\n",
    "\n",
    "        url = ''.join([listing_base_url, str(_listing), '/datarobot-data-scientist-japan'])\n",
    "\n",
    "        print('Processing listing page %s' % ''.join([listing_base_url, str(_listing)]))\n",
    "\n",
    "        try:\n",
    "\n",
    "            #random time delay for scraping\n",
    "            sleep(randint(0,5))\n",
    "\n",
    "            r = requests.get(url, headers=headers)\n",
    "            \n",
    "            doc = lxml.html.fromstring(r.content)\n",
    "\n",
    "            # request status\n",
    "            _dat['job_id'] = _listing\n",
    "            _dat['status_code'] = r.status_code\n",
    "\n",
    "\n",
    "            # warning message, check if exists or contains expired\n",
    "            if doc.cssselect('div.message-inside'):\n",
    "                _dat['alert_message'] = doc.cssselect('div.message-inside')[0].text\n",
    "\n",
    "            # title\n",
    "            _dat['job_title'] = doc.cssselect('div.title h1')[0].text\n",
    "            _dat['company'] = doc.cssselect('div.title h2')[0].text\n",
    "            _dat['location'] = doc.cssselect('div.title h3')[0].text\n",
    "\n",
    "            # posted date\n",
    "            _dat['post_date'] = doc.cssselect('p.submission-date span')[0].get('title')\n",
    "            _dat['views'] = re.compile('\\((\\d*)\\sviews\\)').findall(doc.cssselect('p.submission-date')[0].text_content().replace(',',''))[0]\n",
    "\n",
    "            # body\n",
    "            _dat['body_raw'] = doc.cssselect('div.jobs-board-post-content')[0].text_content()\n",
    "            #_dat['body'] = doc.cssselect('div.jobs-board-post-content p')[1].text_content().replace('\\r\\n',' ')\n",
    "            \n",
    "            _dat['body_p'] = len(doc.cssselect('div.jobs-board-post-content p'))\n",
    "            _dat['body_ul'] = len(doc.cssselect('div.jobs-board-post-content ul'))\n",
    "            #_dat['body_nodes'] = len(doc.cssselect('div.jobs-board-post-content').get_children())\n",
    "        \n",
    "        except:\n",
    "            print('Error getting listing details for: %s' % ''.join([listing_base_url, str(_listing)]))\n",
    "\n",
    "        main_results.append(_dat)\n",
    "\n",
    "\n",
    "    print('Done processing job listings')\n",
    "    return main_results\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    #get results\n",
    "    listings = parse_job_listings(start=16785, end=17128, interval=50)\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(listings, dtype=None)\n",
    "    \n",
    "    print(df.head())\n",
    "\n",
    "    #create filename\n",
    "    #filename = location.replace('--', '_').replace('-', '_').lower() + '.csv'\n",
    "    filename = 'job-listings.csv'\n",
    "    \n",
    "    #get all keys\n",
    "    headings = sorted(list(set().union(*(d.keys() for d in listings))))\n",
    "    \n",
    "    #write to csv file\n",
    "    with open(filename, 'w') as output_file:\n",
    "        dict_writer = csv.DictWriter(output_file, headings)\n",
    "        dict_writer.writeheader()\n",
    "        dict_writer.writerows(listings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[('and', 12), ('experience', 9), ('of', 7), ('with', 7), ('the', 6), ('in', 6), ('to', 5), ('you', 5), ('data', 4), ('will', 3), ('be', 3), ('work', 3), ('skills', 3), ('#1', 2), ('datarobot', 2), ('consulting', 2), ('sales', 2), ('databases', 2), ('technical', 2), ('have', 2), ('developing', 2), ('must', 2), ('or', 2), ('on', 2), ('strong', 2), ('complex', 2), ('do', 2), ('predictive', 2), ('sql', 2), ('customer', 2), ('models', 1), ('environments.', 1), ('following', 1), ('possess', 1), ('environment', 1), ('problems', 1), ('real-time', 1), ('algorithms', 1), ('takes', 1), ('more', 1), ('owen,', 1), ('means', 1), ('r', 1), ('working', 1), ('consultant', 1), ('specifics', 1), ('years', 1), ('it', 1), ('technologies', 1), ('real-world', 1), ('platforms', 1), ('solutions', 1), ('skills:', 1), ('preprocessing', 1), ('datasets', 1), ('want', 1), ('manipulate', 1), ('server,', 1), ('machine', 1), ('analytic', 1), ('using', 1), ('various', 1), ('an', 1), ('customers', 1), ('team', 1), ('ago', 1), ('volume', 1), ('alongside', 1), ('writing', 1), ('prospects', 1), ('requirements,', 1), ('service', 1), ('business', 1), ('views)', 1), ('(1,841', 1), ('involving', 1), ('engineering', 1), ('demonstrations', 1), ('apply', 1), ('communication,', 1), ('for', 1), ('coding', 1), ('discussions', 1), ('opportunities,', 1), ('scenarios.', 1), ('lead', 1), ('current', 1), ('former', 1), ('next', 1), ('japan,', 1), ('oracle,', 1), ('diverse', 1), ('two', 1), ('leading', 1), ('computing', 1), ('hadoop', 1), ('least', 1), ('necessary', 1), ('(python/r)', 1), ('at', 1)]\n",
      "\n",
      "[('and', 26), ('to', 16), ('a', 11), ('data', 9), ('in', 8), ('you', 7), ('of', 7), ('the', 6), ('your', 5), ('for', 5), ('is', 4), ('mobile', 4), ('will', 4), ('free', 4), ('on', 4), ('brands', 3), ('have', 3), ('models', 3), ('implement', 3), ('science,', 3), ('solve', 3), ('use', 3), ('with', 3), ('technology', 3), ('work', 3), ('company', 2), ('growing', 2), ('processing', 2), ('their', 2), ('able', 2), ('including', 2), ('also', 2), ('time', 2), ('our', 2), ('problems', 2), ('do', 2), ('are', 2), ('them', 2), ('problems,', 2), ('be', 2), ('dynamic', 2), ('as', 2), ('algorithms', 2), ('applovin', 2), ('it', 2), ('from', 2), ('love', 2), ('customers', 2), ('re-engage', 2), ('or', 2), ('acquire', 2), ('/', 2), ('know', 2), ('statistics,', 2), ('understand', 2), ('advertising', 2), ('experience', 2), ('computer', 2), ('consumers', 1), ('develop', 1), ('strategy', 1), ('stocked', 1), ('sql,', 1), ('membership', 1), ('(1,614', 1), ('off-the-shelf', 1), ('take', 1), ('natural', 1), ('variety', 1), ('300+', 1), ('ground', 1), ('which', 1), ('means', 1), ('fun.', 1), ('scientist,', 1), ('months', 1), ('preferred.', 1), ('way.', 1), ('strengths', 1), ('lunches', 1), ('solutions', 1), ('moves', 1), ('skills.', 1), ('unlimited', 1), ('send', 1), ('math', 1), ('opentable,', 1), ('machine', 1), ('each', 1), ('us', 1), ('degree', 1), ('beyond', 1), ('enable', 1), ('gym', 1), ('costs', 1), ('other', 1), ('targeting', 1), ('but', 1), ('5', 1), ('fun', 1)]\n",
      "\n",
      "[('and', 33), ('of', 23), ('a', 18), ('the', 17), ('-', 16), ('to', 15), ('in', 13), ('data', 12), ('with', 11), ('experience', 9), ('years', 9), ('for', 8), ('will', 7), ('be', 6), ('capital', 6), ('at', 6), ('new', 6), ('1+', 5), ('one', 5), ('or', 4), ('on', 4), ('by', 4), ('analysis', 4), ('work', 4), ('our', 3), ('professional', 3), ('we', 3), ('an', 3), ('skills', 3), ('least', 3), ('experience-', 3), ('applicable', 3), ('people', 3), ('criminal', 3), ('working', 3), ('analytics', 3), ('employment', 3), ('qualified', 3), ('local', 2), ('top', 2), ('this', 2), ('laws', 2), ('little', 2), ('other', 2), ('consider', 2), ('article', 2), ('passion', 2), ('credit', 2), ('any', 2), ('while', 2), ('are', 2), ('customer', 2), ('organization', 2), ('tests', 2), ('federal,', 2), ('edge', 2), ('qualifications:', 2), ('protected', 2), ('4', 2), ('background', 2), ('where', 2), ('status,', 2), ('is', 2), ('their', 2), ('regarding', 2), ('using', 2), ('implementing', 2), ('analytical', 2), ('entrepreneurial', 2), ('you', 2), ('card', 2), ('environment', 2), ('part', 2), ('workplace.', 2), ('applicants', 2), ('developing', 2), ('life', 2), ('projects', 2), ('management', 2), ('technology', 2), ('inquiries,', 1), ('us', 1), ('orientation,', 1), ('months', 1), ('day', 1), ('initiatives', 1), ('no', 1), ('ordinance', 1), ('elevating', 1), ('consulting', 1), ('want', 1), ('decision-making.', 1), ('applications', 1), ('business', 1), ('leadership', 1), ('amounts', 1), ('5', 1), ('gender', 1), ('also', 1), ('23-a', 1)]\n",
      "\n",
      "[('you', 20), ('and', 16), ('to', 15), ('the', 12), ('in', 10), ('of', 10), ('are', 9), ('with', 8), ('our', 8), ('we', 8), ('a', 8), ('have', 6), ('your', 5), ('will', 4), ('about', 4), ('from', 4), ('work', 4), ('be', 3), ('at', 3), ('all', 3), ('for', 3), ('not', 3), ('it', 3), ('lending', 3), ('that', 3), ('code', 3), ('team', 2), ('people', 2), ('scared', 2), ('do', 2), ('like', 2), ('different', 2), ('any', 2), ('experience', 2), ('available', 2), ('by', 2), ('marketplace', 2), ('solid', 2), ('apply', 2), ('some', 2), ('credit', 2), ('platform.', 2), ('cross-border', 2), ('data', 2), ('can', 2), ('on', 2), ('we’re', 2), ('rate', 2), ('vision', 1), ('market', 1), ('big', 1), ('help', 1), ('(1,260', 1), ('supply', 1), ('doing', 1), ('investors', 1), ('prioritize', 1), ('language', 1), ('(some)', 1), ('libraries', 1), ('willing', 1), ('near', 1), ('low-interest', 1), ('months', 1), ('us.', 1), ('connecting', 1), ('company', 1), ('no', 1), ('traditional', 1), ('solutions', 1), ('this', 1), ('stakeholders.', 1), ('math', 1), ('machine', 1), ('source', 1), ('please', 1), ('amounts', 1), ('fun', 1), ('located', 1), ('databases.', 1), ('figures', 1), ('services', 1), ('being', 1), ('berlin', 1), ('crosslendians:', 1), ('fluent', 1), ('forward', 1), ('future.', 1), ('position?', 1), ('is', 1), ('technical', 1), ('financial', 1), ('very', 1), ('english', 1), ('php', 1), ('through', 1), ('say', 1), ('pioneering', 1), ('programmers', 1), ('awesome', 1)]\n",
      "\n",
      "[('and', 24), ('a', 16), ('with', 14), ('the', 14), ('in', 13), ('our', 12), ('to', 11), ('as', 10), ('for', 9), ('you', 9), ('experience', 8), ('of', 8), ('/', 7), ('learning', 7), ('we', 6), ('data', 5), ('research', 4), ('machine', 4), ('team', 4), ('or', 4), ('should', 4), ('on', 4), ('team,', 3), ('is', 3), ('position', 3), ('san', 3), ('build', 3), ('platform', 3), ('your', 3), ('product', 3), ('are', 3), ('this', 3), ('new', 3), ('role', 3), ('such', 3), ('us', 3), ('comfortable', 3), ('technology', 3), ('looking', 3), ('key', 2), ('candidate', 2), ('be', 2), ('help', 2), ('want', 2), ('about', 2), ('systems', 2), ('people', 2), ('full', 2), ('language', 2), ('using', 2), ('artificial', 2), ('see', 2), ('processing,', 2), ('you’ll', 2), ('information', 2), ('extensive', 2), ('defining', 2), ('science', 2), ('by', 2), ('candidates', 2), ('we’re', 2), ('will', 2), ('real', 2), ('at', 2), ('customers', 2), ('business', 2), ('core', 2), ('msg.ai', 2), ('who', 2), ('include', 2), ('projects', 2), ('platform.', 2), ('intelligence', 2), ('nlp', 2), ('based', 2), ('building', 2), ('work', 2), ('end', 2), ('leaders', 1), ('representation,', 1), ('definition.', 1), ('act', 1), ('big', 1), ('training', 1), ('gaining', 1), ('source', 1), ('short', 1), ('application', 1), ('transition', 1), ('link', 1), ('ground', 1), ('up.', 1), ('world.', 1), ('wow', 1), ('generation', 1), ('scientist,', 1), ('months', 1), ('computation', 1), ('form', 1), ('full-time', 1)]\n",
      "\n",
      "[('and', 33), ('to', 15), ('in', 11), ('a', 9), ('the', 9), ('for', 7), ('as', 7), ('our', 6), ('of', 6), ('are', 5), ('carlisle', 5), ('such', 5), ('&', 4), ('data', 4), ('vehicle', 3), ('is', 3), ('company', 3), ('proficiency', 3), ('market', 3), ('and/or', 3), ('its', 2), ('about', 2), ('please', 2), ('team', 2), ('platforms', 2), ('excellent', 2), ('or', 2), ('on', 2), ('company,', 2), ('new', 2), ('database', 2), ('•', 2), ('be', 2), ('solutions', 2), ('development', 2), ('experience', 2), ('apply', 2), ('industry,', 2), ('analytics', 2), ('strategies,', 2), ('we', 2), ('engineer', 2), ('after-sales', 2), ('complex', 2), ('with', 2), ('clients.', 2), ('learn', 2), ('motor', 2), ('best', 2), ('develop', 1), ('quantitative', 1), ('sql,', 1), ('social', 1), ('research', 1), ('import', 1), ('extraction,', 1), ('plotly,', 1), ('predictive', 1), ('variety', 1), ('written', 1), ('things', 1), ('program', 1), ('consideration,', 1), ('javascript', 1), ('disparate', 1), ('solving', 1), ('capabilities', 1), ('key', 1), ('able', 1), ('enterprise', 1), ('skills—both', 1), ('help', 1), ('maintain', 1), ('expertise', 1), ('want', 1), ('back', 1), ('warehousing,', 1), ('business', 1), ('satisfaction', 1), ('preferred', 1), ('systems', 1), ('exciting', 1), ('(applications', 1), ('but', 1), ('including', 1), ('people', 1), ('benchmarking,', 1), ('manufacturers,', 1), ('javascript.', 1), ('store,', 1), ('where', 1), ('53', 1), ('now', 1), ('visit', 1), ('outstanding', 1), ('motors,', 1), ('analysis.', 1), ('letter', 1), ('twitter', 1), ('expected', 1)]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-26f34ec6f56a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m#''.join([all_text, body])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mword_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m#word_count(df['body_raw'].str.cat(sep=' '))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-134-26f34ec6f56a>\u001b[0m in \u001b[0;36mword_count\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# final choice, use counter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-134-26f34ec6f56a>\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#using split and lower\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#remove_punctuation(s).lower().split()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mword_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import string\n",
    "\n",
    "df\n",
    "\n",
    "def remove_punctuation(s):\n",
    "    \n",
    "    # using string lib and translate\n",
    "    bad_chars = '.,;'\n",
    "    return s.translate(string.maketrans(\"\", \"\", ), bad_chars)\n",
    "\n",
    "def tokenize(s):\n",
    "    \"\"\"return a list of lowercased tokens (words) in a string without punctuation\n",
    "    \"\"\"\n",
    "    #using split and lower\n",
    "    #remove_punctuation(s).lower().split()\n",
    "    return s.lower().split()\n",
    "\n",
    "def word_count(s):\n",
    "    \"\"\"count the number of times each word (lowercased) appears and return a dictionary\n",
    "    \"\"\"\n",
    "    # get individual words\n",
    "    # count original list and loop through\n",
    "    \n",
    "    # alternate: in list, for element i, count identical to end, remove identical, move to next\n",
    "    \n",
    "    # final choice, use counter\n",
    "    words = tokenize(s)\n",
    "    \n",
    "    print()\n",
    "    print(Counter(words).most_common(100))\n",
    "    \n",
    "    return Counter(words)\n",
    "\n",
    "#word_count(df['body_raw'][0:1])\n",
    "#all_text = 'and'\n",
    "\n",
    "for body in df['body_raw']:\n",
    "    #all_text = all_text  body\n",
    "    #''.join([all_text, body])\n",
    "    \n",
    "    word_count(body)\n",
    "    \n",
    "#word_count(df['body_raw'].str.cat(sep=' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
